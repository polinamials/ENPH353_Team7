{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0d0278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 23:10:55.303204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fizzer/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2023-03-25 23:10:55.303227: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    Concatenate,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5e378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 23:10:56.473729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fizzer/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2023-03-25 23:10:56.473745: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-25 23:10:56.473758: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (skynet): /proc/driver/nvidia/version does not exist\n",
      "2023-03-25 23:10:56.473914: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.load_model('trained_model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ede1afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1597, 90, 160, 1)\n",
      "(1597, 2)\n"
     ]
    }
   ],
   "source": [
    "#fine_imgs1 = np.load('data/fine_imgs.npy')\n",
    "#fine_vels1 = np.load('data/fine_vels.npy')\n",
    "fine_imgs2 = np.load('data/fine_imgs_2.npy')\n",
    "fine_vels2 = np.load('data/fine_vels_2.npy')\n",
    "fine_imgs3 = np.load('data/fine_imgs_3.npy')\n",
    "fine_vels3 = np.load('data/fine_vels_3.npy')\n",
    "fine_imgs4 = np.load('data/fine_imgs_4.npy')\n",
    "fine_vels4 = np.load('data/fine_vels_4.npy')\n",
    "fine_imgs = np.concatenate([fine_imgs2, fine_imgs3, fine_imgs4])\n",
    "fine_vels = np.concatenate([fine_vels2,fine_vels3,fine_vels4])\n",
    "print(fine_imgs.shape)\n",
    "print(fine_vels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d132f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('win', fine_imgs[1000])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d87b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = fine_imgs/255\n",
    "vel_data = fine_vels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86f6d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities_to_actions = {\n",
    "    (0.25, 0.0): np.array([1, 0, 0]),\n",
    "    (0.25, 1.0): np.array([0, 1, 0]),\n",
    "    (0.25, -1.0): np.array([0, 0, 1]),\n",
    "}\n",
    "\n",
    "actions = np.array([velocities_to_actions[tuple(i)] for i in vel_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8591eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e36fe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f9cdcad19d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f9cdcad1e50>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7f9cdc212610>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f9cdc2129a0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7f9cdc1d81f0>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x7f9cdc1d83d0>,\n",
       " <keras.layers.reshaping.flatten.Flatten at 0x7f9cdc1d8580>,\n",
       " <keras.layers.core.dense.Dense at 0x7f9cdc1d8850>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x7f9cdc1d8bb0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f9cdc1d8df0>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x7f9cdc1f4370>,\n",
       " <keras.layers.core.dense.Dense at 0x7f9cdc1f45b0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f9cdc1f4af0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cab021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.Sequential()\n",
    "for layer in base_model.layers[:-1]:\n",
    "    new_model.add(layer)\n",
    "    \n",
    "print(type(new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14ecc6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 90, 160, 32)       544       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 22, 40, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 22, 40, 16)        8208      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 10, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 5, 10, 16)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               102528    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,616\n",
      "Trainable params: 0\n",
      "Non-trainable params: 121,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54867834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 90, 160, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 90, 160, 32)       544       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 22, 40, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 22, 40, 16)        8208      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 10, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 5, 10, 16)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               102528    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,067\n",
      "Trainable params: 8,451\n",
      "Non-trainable params: 121,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = new_model.input\n",
    "out = Dense(128, activation='relu')(new_model.output)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Dense(32, activation='relu')(out)\n",
    "out = Dense(3, activation='softmax')(out)\n",
    "finetuner = Model(inp, out)\n",
    "finetuner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68b3c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuner.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fdee8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 0.4196 - accuracy: 0.8183 - val_loss: 0.1239 - val_accuracy: 0.9719\n",
      "Epoch 2/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 0.3760 - accuracy: 0.8309 - val_loss: 0.1163 - val_accuracy: 0.9594\n",
      "Epoch 3/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 0.3629 - accuracy: 0.8269 - val_loss: 0.1697 - val_accuracy: 0.9187\n",
      "Epoch 4/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 0.3512 - accuracy: 0.8418 - val_loss: 0.1019 - val_accuracy: 0.9781\n",
      "Epoch 5/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 0.3658 - accuracy: 0.8356 - val_loss: 0.1477 - val_accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca05cceb0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuner.fit(img_data, actions, batch_size=1, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f835cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned_model/assets\n"
     ]
    }
   ],
   "source": [
    "finetuner.save('finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
